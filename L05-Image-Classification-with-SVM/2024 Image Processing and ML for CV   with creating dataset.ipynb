{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with OpenCV and Scikit-Learn\n",
    "\n",
    "In this notebook, we will explore the basics of image processing using OpenCV and build a simple image classifier using Scikit-Learn. We will perform the following steps:\n",
    "1. Load and preprocess images using OpenCV.\n",
    "2. Extract features from the images.\n",
    "3. Train a machine learning model on the extracted features.\n",
    "4. Evaluate the model's performance.\n",
    "\n",
    "## Step 1: Importing Libraries\n",
    "\n",
    "First, we need to import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing the Dataset\n",
    "\n",
    "For this exercise, we need a dataset of images. We will create two folders: `cats` and `dogs`, each containing images of cats and dogs, respectively.\n",
    "\n",
    "### Number of Images\n",
    "\n",
    "To train a basic machine learning model, you should have at least 100 images in each folder (cats and dogs). However, the more images you have, the better your model is likely to perform. Ideally, aim for 500-1000 images per category for better accuracy.\n",
    "\n",
    "### Folder Structure\n",
    "\n",
    "The folder structure should look like this:\n",
    "\n",
    "data/\n",
    "cats/\n",
    "dogs/\n",
    "data/\n",
    "\n",
    "cats/\n",
    "cat1.jpg\n",
    "cat2.jpg\n",
    "...\n",
    "dogs/\n",
    "dog1.jpg\n",
    "dog2.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ensure that the images are named appropriately and stored in the correct folders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Loading and Preprocessing Images\n",
    "\n",
    "We will load the images, convert them to grayscale, resize them to a uniform size, and flatten them into a 1D array to use as features for our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        if label == 'cats':\n",
    "            label_id = 0\n",
    "        elif label == 'dogs':\n",
    "            label_id = 1\n",
    "        else:\n",
    "            continue\n",
    "        for filename in os.listdir(os.path.join(folder, label)):\n",
    "            img_path = os.path.join(folder, label, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "            img = cv2.resize(img, (64, 64))  # Resize image to 64x64\n",
    "            images.append(img.flatten())  # Flatten the image to 1D array\n",
    "            labels.append(label_id)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load images from the dataset folder\n",
    "X, y = load_images('data')\n",
    "\n",
    "# Display a sample image\n",
    "plt.imshow(X[0].reshape(64, 64), cmap='gray')\n",
    "plt.title('Sample Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Splitting the Data\n",
    "\n",
    "We will split the data into training and testing sets using the `train_test_split` function from Scikit-Learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training a Machine Learning Model\n",
    "\n",
    "### What is SVM (Support Vector Machine)?\n",
    "\n",
    "Support Vector Machine (SVM) is a supervised machine learning algorithm that can be used for both classification and regression tasks. However, it is mostly used for classification problems. The objective of the SVM algorithm is to find a hyperplane in an N-dimensional space (N is the number of features) that distinctly classifies the data points.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Hyperplane:** A decision boundary that separates different classes in the feature space. In 2D, it's a line; in 3D, it's a plane.\n",
    "- **Support Vectors:** Data points that are closest to the hyperplane and influence its position and orientation. These points help in maximizing the margin of the classifier.\n",
    "- **Margin:** The distance between the hyperplane and the closest data points from either class. SVM aims to maximize this margin.\n",
    "\n",
    "### Why Use SVM?\n",
    "\n",
    "- **Effective in high-dimensional spaces:** SVM is very effective when the number of features is large.\n",
    "- **Memory efficient:** It uses a subset of training points (support vectors) in the decision function, making it memory efficient.\n",
    "- **Versatile:** Different kernel functions can be specified for the decision function. Common kernels include linear, polynomial, and radial basis function (RBF).\n",
    "\n",
    "### What does `SVC(kernel='linear')` mean?\n",
    "\n",
    "`SVC` stands for Support Vector Classification, which is a class in the Scikit-Learn library used to implement the SVM algorithm for classification tasks. The `kernel` parameter in the `SVC` class specifies the type of hyperplane used to separate the data.\n",
    "\n",
    "#### Kernel Types:\n",
    "\n",
    "- **Linear Kernel:** The data is linearly separable (i.e., a straight line or hyperplane can separate the data). This is the simplest kernel.\n",
    "  - When we use `SVC(kernel='linear')`, it means we are using a linear kernel for our SVM. This kernel is appropriate when the data can be separated by a straight line (or hyperplane in higher dimensions).\n",
    "- **Polynomial Kernel:** The data is not linearly separable, but a polynomial function of the input features can separate the data.\n",
    "- **Radial Basis Function (RBF) Kernel:** The data is not linearly separable, but mapping the data into a higher-dimensional space using a Gaussian (RBF) function can separate the data.\n",
    "\n",
    "### Training the SVM Model\n",
    "\n",
    "We will use a Support Vector Machine (SVM) classifier from Scikit-Learn to train our model on the extracted features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM classifier\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Conclusion\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded and preprocessed images using OpenCV.\n",
    "2. Extracted features by flattening the grayscale images.\n",
    "3. Trained an SVM classifier on the extracted features.\n",
    "4. Evaluated the model's performance.\n",
    "\n",
    "This is a basic introduction to image classification using classical machine learning techniques. For more advanced applications, consider exploring deep learning models like Convolutional Neural Networks (CNNs) using libraries such as TensorFlow or PyTorch.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
